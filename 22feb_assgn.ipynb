{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a7554-cec6-4c70-86f1-0616b08b4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "Go to this given URL and solve the following questions\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb982c55-d159-498e-bc24-b7d336aaef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Write a python program to extract the video URL of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen as ureq\n",
    "\n",
    "# URL of the webpage with the videos\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and get the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object with the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the video tags in the HTML\n",
    "video_tags = soup.find_all('video')\n",
    "\n",
    "# Extract the video URL of the first five videos\n",
    "for i, video_tag in enumerate(video_tags):\n",
    "    if i == 5:\n",
    "        break\n",
    "    video_url = video_tag['src']\n",
    "    print(f\"Video {i + 1}: {video_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5061048f-6aeb-4cee-9775-5eb730f42675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage with the videos\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Send a GET request to the URL and get the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object with the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the video tags in the HTML\n",
    "video_tags = soup.find_all('video')\n",
    "\n",
    "# Extract the URL of the video thumbnails of the first five videos\n",
    "for i, video_tag in enumerate(video_tags):\n",
    "    if i == 5:\n",
    "        break\n",
    "    thumbnail_url = video_tag.find('img')['src']\n",
    "    print(f\"Thumbnail {i + 1}: {thumbnail_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8babdef1-e074-4721-bed6-c2decb7012c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.84.0-py2.py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3.0.0dev,>=1.19.0\n",
      "  Downloading google_auth-2.17.2-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.21.11)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.1.1)\n",
      "Installing collected packages: pyasn1, uritemplate, rsa, pyasn1-modules, httplib2, googleapis-common-protos, cachetools, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.3.0 google-api-core-2.11.0 google-api-python-client-2.84.0 google-auth-2.17.2 google-auth-httplib2-0.1.0 googleapis-common-protos-1.59.0 httplib2-0.22.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.9 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4bb646-e641-4f92-87c6-056a6e74c7ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?part=id&channelId=https%3A%2F%2Fwww.youtube.com%2F%40PW-Foundation%2Fvideos&maxResults=5&order=date&type=video&key=AIzaSyD5u49NFle7CQ4a_nzUXUNl5Tn-IiGAC4I&alt=json returned \"YouTube Data API v3 has not been used in project 684080290979 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/youtube.googleapis.com/overview?project=684080290979 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\". Details: \"[{'message': 'YouTube Data API v3 has not been used in project 684080290979 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/youtube.googleapis.com/overview?project=684080290979 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.', 'domain': 'usageLimits', 'reason': 'accessNotConfigured', 'extendedHelp': 'https://console.developers.google.com'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m num_videos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Call the API to get the list of videos from the channel\u001b[39;00m\n\u001b[1;32m     13\u001b[0m videos \u001b[38;5;241m=\u001b[39m \u001b[43myoutube\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxResults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_videos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m---> 19\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Extract the video IDs from the API response\u001b[39;00m\n\u001b[1;32m     22\u001b[0m video_ids \u001b[38;5;241m=\u001b[39m [video[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideoId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m videos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m     callback(resp)\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/search?part=id&channelId=https%3A%2F%2Fwww.youtube.com%2F%40PW-Foundation%2Fvideos&maxResults=5&order=date&type=video&key=AIzaSyD5u49NFle7CQ4a_nzUXUNl5Tn-IiGAC4I&alt=json returned \"YouTube Data API v3 has not been used in project 684080290979 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/youtube.googleapis.com/overview?project=684080290979 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\". Details: \"[{'message': 'YouTube Data API v3 has not been used in project 684080290979 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/youtube.googleapis.com/overview?project=684080290979 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.', 'domain': 'usageLimits', 'reason': 'accessNotConfigured', 'extendedHelp': 'https://console.developers.google.com'}]\">"
     ]
    }
   ],
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel homepage\n",
    "url = 'https://www.youtube.com/channel/your_channel_id_here/videos'\n",
    "\n",
    "# Send a GET request to the URL and get the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object with the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the video elements in the HTML\n",
    "video_elements = soup.find_all('a', {'class': 'ytd-thumbnail'})\n",
    "\n",
    "# Extract the number of views of the first five videos\n",
    "for i, video_element in enumerate(video_elements[:5]):\n",
    "    # Get the URL of the video page\n",
    "    video_url = 'https://www.youtube.com' + video_element['href']\n",
    "    # Send a GET request to the video page and get the response\n",
    "    video_response = requests.get(video_url)\n",
    "    # Create a BeautifulSoup object with the response content\n",
    "    video_soup = BeautifulSoup(video_response.content, 'html.parser')\n",
    "    # Find the element that contains the number of views\n",
    "    views_element = video_soup.find('span', {'class': 'view-count'})\n",
    "    # Extract the number of views from the element text\n",
    "    views = views_element.text.strip()\n",
    "    # Get the title of the video\n",
    "    title_element = video_soup.find('h1', {'class': 'title'})\n",
    "    title = title_element.text.strip()\n",
    "    # Print the title and number of views\n",
    "    print(f\"Video {i + 1}: {title} - {views}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73efb50f-32f4-4dec-9653-21fee790e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel homepage\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Send a GET request to the URL and get the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object with the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the video elements in the HTML\n",
    "video_elements = soup.find_all('a', {'class': 'ytd-thumbnail'})\n",
    "\n",
    "# Extract the number of views of the first five videos\n",
    "for i, video_element in enumerate(video_elements[:5]):\n",
    "    # Get the URL of the video page\n",
    "    video_url = 'https://www.youtube.com' + video_element['href']\n",
    "    # Send a GET request to the video page and get the response\n",
    "    video_response = requests.get(video_url)\n",
    "    # Create a BeautifulSoup object with the response content\n",
    "    video_soup = BeautifulSoup(video_response.content, 'html.parser')\n",
    "    # Find the element that contains the number of views\n",
    "    view_element = video_soup.find('span', {'class': 'view-count'})\n",
    "    # Extract the number of views from the element text\n",
    "    views = view_element.text.strip().split()[0]\n",
    "    # Get the title of the video\n",
    "    title_element = video_soup.find('h1', {'class': 'title'})\n",
    "    title = title_element.text.strip()\n",
    "    # Print the title and number of views\n",
    "    print(f\"Video {i + 1}: {title} - {views}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8398c4-e1a0-440b-83fd-fe55157581ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the YouTube channel homepage\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Send a GET request to the URL and get the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object with the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the video elements in the HTML\n",
    "video_elements = soup.find_all('a', {'class': 'ytd-thumbnail'})\n",
    "\n",
    "# Extract the time of posting of the first five videos\n",
    "for i, video_element in enumerate(video_elements[:5]):\n",
    "    # Get the URL of the video page\n",
    "    video_url = 'https://www.youtube.com' + video_element['href']\n",
    "    # Send a GET request to the video page and get the response\n",
    "    video_response = requests.get(video_url)\n",
    "    # Create a BeautifulSoup object with the response content\n",
    "    video_soup = BeautifulSoup(video_response.content, 'html.parser')\n",
    "    # Find the element that contains the time of posting\n",
    "    time_element = video_soup.find('div', {'id': 'date'})\n",
    "    # Extract the time of posting from the element text\n",
    "    time = time_element.text.strip()\n",
    "    # Get the title of the video\n",
    "    title_element = video_soup.find('h1', {'class': 'title'})\n",
    "    title = title_element.text.strip()\n",
    "    # Print the title and time of posting\n",
    "    print(f\"Video {i + 1}: {title} - {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90599e7-7165-42a5-b80a-f83292900daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
